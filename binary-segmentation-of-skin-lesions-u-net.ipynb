{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1335230,"sourceType":"datasetVersion","datasetId":775382}],"dockerImageVersionId":30407,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is for binary segmentation for skin lesion detection. ISIC dataset is used. I used the TensorFlow data processing pipeline (tf.io) for data preprocessing, and I augmented the training data using the albumentations library. The loss function employed a combination of BCE and dice-loss, while callbacks such as ReduceLRonPlateau were used for enhancing the training process. Additionally, earlystopping and modelcheckpoint callbacks were implemented to prevent overfitting and save the best performing model.**","metadata":{}},{"cell_type":"markdown","source":"# Imports and Preparing Environment","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf \nfrom tensorflow.keras import layers\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\nfrom tensorflow.keras import backend as K\nimport albumentations as A\nfrom functools import partial\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-21T14:27:08.914119Z","iopub.execute_input":"2023-12-21T14:27:08.914855Z","iopub.status.idle":"2023-12-21T14:27:20.031524Z","shell.execute_reply.started":"2023-12-21T14:27:08.914815Z","shell.execute_reply":"2023-12-21T14:27:20.030574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 42\nnp.random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:20.033422Z","iopub.execute_input":"2023-12-21T14:27:20.033972Z","iopub.status.idle":"2023-12-21T14:27:20.038651Z","shell.execute_reply.started":"2023-12-21T14:27:20.033935Z","shell.execute_reply":"2023-12-21T14:27:20.037687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:20.039927Z","iopub.execute_input":"2023-12-21T14:27:20.04054Z","iopub.status.idle":"2023-12-21T14:27:20.053645Z","shell.execute_reply.started":"2023-12-21T14:27:20.040507Z","shell.execute_reply":"2023-12-21T14:27:20.052792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:20.054969Z","iopub.execute_input":"2023-12-21T14:27:20.0558Z","iopub.status.idle":"2023-12-21T14:27:20.064957Z","shell.execute_reply.started":"2023-12-21T14:27:20.055761Z","shell.execute_reply":"2023-12-21T14:27:20.064054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.list_physical_devices('GPU')","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:20.06856Z","iopub.execute_input":"2023-12-21T14:27:20.069122Z","iopub.status.idle":"2023-12-21T14:27:20.346911Z","shell.execute_reply.started":"2023-12-21T14:27:20.069066Z","shell.execute_reply":"2023-12-21T14:27:20.345902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting the data","metadata":{}},{"cell_type":"code","source":"os.listdir('/kaggle/input/isic2018-challenge-task1-data-segmentation')","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:20.348073Z","iopub.execute_input":"2023-12-21T14:27:20.348403Z","iopub.status.idle":"2023-12-21T14:27:20.371Z","shell.execute_reply.started":"2023-12-21T14:27:20.348369Z","shell.execute_reply":"2023-12-21T14:27:20.370064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img_folder_path = \"/kaggle/input/isic2018-challenge-task1-data-segmentation/ISIC2018_Task1-2_Training_Input\"\ntrain_label_folder_path = \"/kaggle/input/isic2018-challenge-task1-data-segmentation/ISIC2018_Task1_Training_GroundTruth\"\nval_folder_path = \"/kaggle/input/isic2018-challenge-task1-data-segmentation/ISIC2018_Task1-2_Validation_Input\"\ntest_folder_path = \"/kaggle/input/isic2018-challenge-task1-data-segmentation/ISIC2018_Task1-2_Test_Input\"","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:20.372214Z","iopub.execute_input":"2023-12-21T14:27:20.372513Z","iopub.status.idle":"2023-12-21T14:27:20.377462Z","shell.execute_reply.started":"2023-12-21T14:27:20.372484Z","shell.execute_reply":"2023-12-21T14:27:20.376373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking if paths are correct\nexist_condition = os.path.exists(train_img_folder_path) and os.path.exists(train_label_folder_path) and os.path.exists(val_folder_path) and os.path.exists(test_folder_path)\nprint(\"Files not found\") if exist_condition == False else None","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:20.378848Z","iopub.execute_input":"2023-12-21T14:27:20.37929Z","iopub.status.idle":"2023-12-21T14:27:20.387028Z","shell.execute_reply.started":"2023-12-21T14:27:20.379251Z","shell.execute_reply":"2023-12-21T14:27:20.386065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize the data","metadata":{"_kg_hide-input":false}},{"cell_type":"code","source":"# This array contains paths for the images. Folder contains a text file, we only want images I used endswith function to get jpg files\ntrain_images_path = np.sort([os.path.join(train_img_folder_path, i) for i in os.listdir(train_img_folder_path) if i.endswith('.jpg')])\ntrain_labels_path = np.sort([os.path.join(train_label_folder_path, i) for i in os.listdir(train_label_folder_path) if i.endswith('.png')])\ntest_images_path = np.sort([os.path.join(test_folder_path, i) for i in os.listdir(test_folder_path) if i.endswith('.jpg')])","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:20.387997Z","iopub.execute_input":"2023-12-21T14:27:20.388261Z","iopub.status.idle":"2023-12-21T14:27:22.070236Z","shell.execute_reply.started":"2023-12-21T14:27:20.388235Z","shell.execute_reply":"2023-12-21T14:27:22.069287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_split = 0.8\nval_images_path = train_images_path[int(train_split*len(train_images_path)):]\nval_labels_path = train_labels_path[int(train_split*len(train_labels_path)):]\ntrain_images_path = train_images_path[:int(train_split*len(train_images_path))]\ntrain_labels_path = train_labels_path[:int(train_split*len(train_labels_path))]","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:22.071383Z","iopub.execute_input":"2023-12-21T14:27:22.071686Z","iopub.status.idle":"2023-12-21T14:27:22.078248Z","shell.execute_reply.started":"2023-12-21T14:27:22.071657Z","shell.execute_reply":"2023-12-21T14:27:22.077063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_images_path) + len(val_images_path)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:22.079618Z","iopub.execute_input":"2023-12-21T14:27:22.080015Z","iopub.status.idle":"2023-12-21T14:27:22.09447Z","shell.execute_reply.started":"2023-12-21T14:27:22.079975Z","shell.execute_reply":"2023-12-21T14:27:22.093385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing first train image with its label.\nimg1 = Image.open(train_images_path[0])\nimg1.thumbnail((512, 512))\nimg1_label = Image.open(train_labels_path[0])\nimg1_label.thumbnail((512, 512))\nplt.subplots(figsize=(6,3))\nplt.subplot(1,2,1)\nplt.imshow(img1)\nplt.axis('off')\nplt.subplot(1,2,2)\nplt.imshow(img1_label, cmap='gray')\nplt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:22.095889Z","iopub.execute_input":"2023-12-21T14:27:22.096308Z","iopub.status.idle":"2023-12-21T14:27:22.452575Z","shell.execute_reply.started":"2023-12-21T14:27:22.09627Z","shell.execute_reply":"2023-12-21T14:27:22.451531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function plots 25 random images with segmantation mask.\ndef plot_segmentation_images(image_path, image_label_path, size=512, Random=True):\n    figure = plt.subplots(figsize=(25, 25))\n    \n    # plotting rows iterating through \n    for i in range(25): \n        random_number = np.random.randint(len(image_path)) if Random else i\n        img = Image.open(image_path[random_number])\n        img_label = Image.open(image_label_path[random_number])\n        img = img.resize((size, size))\n        img_label = img_label.resize((size, size))\n        img = np.array(img)\n        img_label = np.array(img_label)\n        mask = np.ma.masked_where(img_label>0, img_label)\n        img_label_mask = np.ma.masked_array(img_label, mask)\n        img_name = image_label_path[random_number].split('/')[-1]\n\n        plt.subplot(5, 5, i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(img, cmap='gray')\n        plt.imshow(img_label_mask, cmap='jet', alpha=0.4)\n        plt.xlabel(f'ID: {img_name}', fontsize=15)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:22.453924Z","iopub.execute_input":"2023-12-21T14:27:22.454189Z","iopub.status.idle":"2023-12-21T14:27:22.464697Z","shell.execute_reply.started":"2023-12-21T14:27:22.454163Z","shell.execute_reply":"2023-12-21T14:27:22.463856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plots 25 random train images.\nplot_segmentation_images(train_images_path, train_labels_path)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-21T14:27:22.47029Z","iopub.execute_input":"2023-12-21T14:27:22.470597Z","iopub.status.idle":"2023-12-21T14:27:34.130021Z","shell.execute_reply.started":"2023-12-21T14:27:22.470567Z","shell.execute_reply":"2023-12-21T14:27:34.128609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading The Data","metadata":{}},{"cell_type":"markdown","source":"Few notes before starting. In a previous version of my code, I used Imagedatagenerator(). However, this method is now deprecated and not recommended by TensorFlow documentation. Additionally, it is much slower than using tf.Data, which is what I am using in this version of my code.\n\nI will also be using a portion of the training data as the validation input since there is no validation ground truth in the dataset. Finally, I will be utilizing the pipelining features of tf.data even though the dataset is relatively small, as it can help improve performance and scalability in larger datasets.","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = 256\nIMG_CHANNELS = 3\nbatch_size = 8\nbuffer_size = 1000\nsteps_per_epoch = len(train_images_path) // batch_size\nAUTOTUNE = tf.data.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:34.131901Z","iopub.execute_input":"2023-12-21T14:27:34.132427Z","iopub.status.idle":"2023-12-21T14:27:34.138098Z","shell.execute_reply.started":"2023-12-21T14:27:34.132372Z","shell.execute_reply":"2023-12-21T14:27:34.137115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_ds = tf.data.Dataset.list_files(train_images_path, seed=seed)\ny_train_ds = tf.data.Dataset.list_files(train_labels_path, seed=seed)\nx_val_ds = tf.data.Dataset.list_files(val_images_path, seed=seed)\ny_val_ds = tf.data.Dataset.list_files(val_labels_path, seed=seed)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:34.139404Z","iopub.execute_input":"2023-12-21T14:27:34.13974Z","iopub.status.idle":"2023-12-21T14:27:52.052523Z","shell.execute_reply.started":"2023-12-21T14:27:34.13971Z","shell.execute_reply":"2023-12-21T14:27:52.051171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_image(img_path, size=(256,256)):\n    image = tf.io.read_file(img_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, size)\n    return image\n\ndef parse_gt(gt_path, size=(256,256)):\n    gt = tf.io.read_file(gt_path)\n    gt = tf.image.decode_png(gt, channels=1)\n    gt = tf.image.resize(gt, size, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    gt = tf.where(gt == 0, 0, 1)\n    gt = tf.image.convert_image_dtype(gt, tf.int32)\n    return gt","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:52.056084Z","iopub.execute_input":"2023-12-21T14:27:52.056574Z","iopub.status.idle":"2023-12-21T14:27:52.067911Z","shell.execute_reply.started":"2023-12-21T14:27:52.056537Z","shell.execute_reply":"2023-12-21T14:27:52.066534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_ds = x_train_ds.map(parse_image)\ny_train_ds = y_train_ds.map(parse_gt)\nx_val_ds = x_val_ds.map(parse_image)\ny_val_ds = y_val_ds.map(parse_gt)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:52.069692Z","iopub.execute_input":"2023-12-21T14:27:52.070346Z","iopub.status.idle":"2023-12-21T14:27:52.303543Z","shell.execute_reply.started":"2023-12-21T14:27:52.070289Z","shell.execute_reply":"2023-12-21T14:27:52.302417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Train x size: {len(x_train_ds)}')\nprint(f'Validation x size: {len(x_val_ds)}')\nprint(f'Train y size: {len(y_train_ds)}')\nprint(f'Validation y size: {len(y_val_ds)}')","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:52.305385Z","iopub.execute_input":"2023-12-21T14:27:52.305829Z","iopub.status.idle":"2023-12-21T14:27:52.314645Z","shell.execute_reply.started":"2023-12-21T14:27:52.305778Z","shell.execute_reply":"2023-12-21T14:27:52.313393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.data.Dataset.zip((x_train_ds, y_train_ds))\nval_ds = tf.data.Dataset.zip((x_val_ds, y_val_ds))","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:52.315916Z","iopub.execute_input":"2023-12-21T14:27:52.316247Z","iopub.status.idle":"2023-12-21T14:27:52.333092Z","shell.execute_reply.started":"2023-12-21T14:27:52.316212Z","shell.execute_reply":"2023-12-21T14:27:52.331742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment(image, mask, size=(256, 256)):\n  transforms = A.Compose([\n      A.OneOf([\n          A.Transpose(),\n          A.VerticalFlip(),\n          A.HorizontalFlip(),\n          A.RandomRotate90(),\n          A.NoOp()], p=0.75),\n\n      A.ShiftScaleRotate(p=0.1),\n      A.GridDistortion(p=0.1),\n      A.ElasticTransform(p=0.1),\n\n      A.OneOf([\n          A.RandomBrightnessContrast(),    \n          A.RandomGamma()], p=0.2)\n      \n    ], additional_targets={'mask': 'mask'})\n\n  data = {\"image\":image, \"mask\":mask}\n  aug_data = transforms(**data)\n\n  aug_img = aug_data[\"image\"]\n  aug_img = tf.cast(aug_img, tf.float32)\n\n  aug_mask = aug_data[\"mask\"]\n  # Making sure labels are binary (background or label)\n  aug_mask = np.where(aug_mask == 0, 0, 1)\n  aug_mask = tf.cast(aug_mask, tf.int32)\n  return aug_img, aug_mask\n\n# I got \"Tensor has no attribute .numpy() method\" error. To fix this I used tf.numpy_function()\ndef process_data(image, mask, h=256, w=256):\n  image, mask = tf.numpy_function(func=augment, inp=[image, mask], Tout=(tf.float32, tf.int32))\n  # The datasets loses its shape after applying a tf.numpy_function, so this is \n  # necessary for the sequential model and when inheriting from the model class.\n  image.set_shape((h, w, 3))\n  mask.set_shape((h, w, 1))\n  return image, mask","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:52.334939Z","iopub.execute_input":"2023-12-21T14:27:52.335278Z","iopub.status.idle":"2023-12-21T14:27:52.34721Z","shell.execute_reply.started":"2023-12-21T14:27:52.335249Z","shell.execute_reply":"2023-12-21T14:27:52.345963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = (\n    train_ds\n    .cache()\n    .map(partial(process_data))\n    .batch(batch_size)\n    .repeat()\n    .prefetch(buffer_size=AUTOTUNE)\n)\n\n# Not appliyingg augmentation on validation data.\nval_ds = (\n    val_ds\n    .cache()\n    .batch(batch_size)\n    .repeat()\n    .prefetch(buffer_size=AUTOTUNE)\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:52.348474Z","iopub.execute_input":"2023-12-21T14:27:52.349276Z","iopub.status.idle":"2023-12-21T14:27:52.45383Z","shell.execute_reply.started":"2023-12-21T14:27:52.349247Z","shell.execute_reply":"2023-12-21T14:27:52.452524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds.element_spec","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:52.455259Z","iopub.execute_input":"2023-12-21T14:27:52.45559Z","iopub.status.idle":"2023-12-21T14:27:52.462069Z","shell.execute_reply.started":"2023-12-21T14:27:52.455558Z","shell.execute_reply":"2023-12-21T14:27:52.461103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image, label in train_ds.take(1):\n    print(image.shape)\n    print(label.shape)\n    plt.subplots(figsize=(25, 25))\n    for i in range(0, batch_size, 2):\n        plt.subplot(batch_size, 2, i+1)\n        plt.imshow(image[i])\n        plt.axis('off')\n        plt.subplot(batch_size, 2, i+2)\n        plt.imshow(label[i], cmap='gray')\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n    break","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-21T14:27:52.4634Z","iopub.execute_input":"2023-12-21T14:27:52.463702Z","iopub.status.idle":"2023-12-21T14:27:54.402788Z","shell.execute_reply.started":"2023-12-21T14:27:52.463673Z","shell.execute_reply":"2023-12-21T14:27:54.401924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = (\n    tf.data.Dataset.list_files(test_images_path)\n    .map(parse_image)\n    .batch(1))","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:54.404481Z","iopub.execute_input":"2023-12-21T14:27:54.404801Z","iopub.status.idle":"2023-12-21T14:27:54.789471Z","shell.execute_reply.started":"2023-12-21T14:27:54.404769Z","shell.execute_reply":"2023-12-21T14:27:54.788363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# Functions to build the encoder path\ndef conv_block(inp, filters, padding='same', activation='relu'): \n    x = Conv2D(filters, (3, 3), padding=padding, activation=activation)(inp)\n    x = Conv2D(filters, (3, 3), padding=padding)(x)\n    x = BatchNormalization(axis=3)(x)\n    x = Activation(activation)(x)\n    return x\n\ndef encoder_block(inp, filters, padding='same', pool_stride=2, activation='relu'):\n    # Encoder block of a UNet passes the result from the convolution block\n    # above to a max pooling layer\n    x = conv_block(inp, filters, padding, activation)\n    p = MaxPooling2D(pool_size=(2, 2), strides=pool_stride)(x)\n    return x, p\n\n\n# Function to build decoder path\ndef decoder_block(inp,filters,concat_layer,padding='same'):\n    # Upsample the feature maps\n    x = Conv2DTranspose(filters, (2,2), strides=(2,2), padding=padding)(inp)\n    x = concatenate([x, concat_layer]) # Concatenation/Skip conncetion with conjuagte encoder\n    x = conv_block(x, filters) # Passed into the convolution block above\n    return x\n# Building the first block\ndef build_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS=3):\n    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n    d1, p1=encoder_block(inputs, 64)\n    d2, p2=encoder_block(p1, 128)\n    d3, p3=encoder_block(p2, 256)\n    d4, p4=encoder_block(p3, 512)\n    mid = conv_block(p4, 1024) # Midsection\n    e2 = decoder_block(mid, 512, d4) # Conjugate of encoder 4\n    e3 = decoder_block(e2, 256, d3) # Conjugate of encoder 3\n    e4 = decoder_block(e3, 128, d2) # Conjugate of encoder 2 \n    # o1 = Conv2D(1, (1,1), activation=None)(e4) # Output from 2nd last decoder\n    e5 = decoder_block(e4, 64, d1) # Conjugate of encoder 1\n    outputs = Conv2D(1, (1, 1),activation='sigmoid')(e5) #Final Output\n    model = tf.keras.Model(inputs=[inputs], outputs=[outputs], name='Unet')\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:54.790743Z","iopub.execute_input":"2023-12-21T14:27:54.791059Z","iopub.status.idle":"2023-12-21T14:27:54.80707Z","shell.execute_reply.started":"2023-12-21T14:27:54.79103Z","shell.execute_reply":"2023-12-21T14:27:54.806012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Metrics\ndef dice_coef(y_true, y_pred):\n    smooth = 1e-7\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef jacard(y_true, y_pred):\n\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n\n    return intersection/union","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:54.808313Z","iopub.execute_input":"2023-12-21T14:27:54.808705Z","iopub.status.idle":"2023-12-21T14:27:54.821991Z","shell.execute_reply.started":"2023-12-21T14:27:54.808665Z","shell.execute_reply":"2023-12-21T14:27:54.821077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loss\n\ndef bce_dice_loss(y_true, y_pred):\n    y_true = K.cast(y_true, dtype=y_pred.dtype)\n    bce = K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)\n    dice = dice_coef(y_true, y_pred)\n    return bce - K.log(dice)\n\ndef bce_dice_loss_log(y_true, y_pred):\n    y_true = K.cast(y_true, dtype=y_pred.dtype)\n    bce = K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)\n    dice = dice_coef(y_true, y_pred)\n    return bce + 1 - dice","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:54.823352Z","iopub.execute_input":"2023-12-21T14:27:54.82377Z","iopub.status.idle":"2023-12-21T14:27:54.835606Z","shell.execute_reply.started":"2023-12-21T14:27:54.82373Z","shell.execute_reply":"2023-12-21T14:27:54.834815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model(IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss=bce_dice_loss_log, \n              metrics=[dice_coef, jacard, 'accuracy'])\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:54.836973Z","iopub.execute_input":"2023-12-21T14:27:54.837255Z","iopub.status.idle":"2023-12-21T14:27:55.304507Z","shell.execute_reply.started":"2023-12-21T14:27:54.837228Z","shell.execute_reply":"2023-12-21T14:27:55.303677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps_per_epoch = int(len(train_images_path)*0.8 // batch_size)\nval_steps = int(len(train_images_path)*0.2 // batch_size)\nprint(f\"Batch Size: {batch_size}\\nSteps_per_epoch: {steps_per_epoch}\\nValidation_steps: {val_steps}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:55.305681Z","iopub.execute_input":"2023-12-21T14:27:55.305989Z","iopub.status.idle":"2023-12-21T14:27:55.311679Z","shell.execute_reply.started":"2023-12-21T14:27:55.30596Z","shell.execute_reply":"2023-12-21T14:27:55.3107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DisplaySegmentationResults(Callback):\n    def __init__(self, dataset, num_images=1):\n        super(DisplaySegmentationResults, self).__init__()\n        self.dataset = dataset\n        self.num_images = num_images\n\n    def on_epoch_end(self, epoch, logs=None):\n        for i, (image, mask) in enumerate(self.dataset.take(self.num_images)):\n            # Predict the mask for the image\n            predicted_mask = self.model.predict(image[0][np.newaxis, ...], verbose=0)[0]\n            predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n\n            fig, ax = plt.subplots(1, 3, figsize=(6, 2))\n            ax[0].imshow(image[0])\n            ax[0].set_title('Input Image')\n            ax[1].imshow(mask[0, ..., 0], cmap='gray')\n            ax[1].set_title('Ground Truth Mask')\n            ax[2].imshow(predicted_mask[..., 0], cmap='gray')\n            ax[2].set_title('Predicted Mask')\n\n            for a in ax:\n                a.axis('off')\n\n            plt.suptitle(f\"Epoch {epoch+1}, Sample {i+1}\")\n            plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:55.312919Z","iopub.execute_input":"2023-12-21T14:27:55.313279Z","iopub.status.idle":"2023-12-21T14:27:55.325999Z","shell.execute_reply.started":"2023-12-21T14:27:55.313238Z","shell.execute_reply":"2023-12-21T14:27:55.324972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [\n    EarlyStopping(monitor='val_dice_coef', patience=10, mode='max'),\n    ModelCheckpoint(filepath='saved_model.h5', monitor='val_dice_coef', save_best_only=True),\n    ReduceLROnPlateau(monitor='val_dice_coef', factor=0.2, patience=5, verbose=1, min_lr=5e-7),\n    DisplaySegmentationResults(val_ds)\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-21T14:27:55.327224Z","iopub.execute_input":"2023-12-21T14:27:55.327586Z","iopub.status.idle":"2023-12-21T14:27:55.339164Z","shell.execute_reply.started":"2023-12-21T14:27:55.327547Z","shell.execute_reply":"2023-12-21T14:27:55.338102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nresults = model.fit(train_ds, epochs=12, verbose=2,\n                    steps_per_epoch=steps_per_epoch,\n                    validation_steps=val_steps,\n                    validation_data=val_ds,\n                    callbacks=callbacks)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-21T14:27:55.340467Z","iopub.execute_input":"2023-12-21T14:27:55.341125Z","iopub.status.idle":"2023-12-21T15:16:50.87195Z","shell.execute_reply.started":"2023-12-21T14:27:55.341095Z","shell.execute_reply":"2023-12-21T15:16:50.870892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(8, 10))\n\nplt.subplot(2,2,1)\nplt.plot(results.history['dice_coef'])\nplt.plot(results.history['val_dice_coef'])\nplt.title('dice_coef vs Epoch')\nplt.xlabel('Epochs')\nplt.ylabel('dice_coef')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.tight_layout()\n\nplt.subplot(2,2,2)\nplt.plot(results.history['jacard'])\nplt.plot(results.history['val_jacard'])\nplt.title('Jacard vs Epoch')\nplt.xlabel('Epochs')\nplt.ylabel('Jacard')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.tight_layout()\n\nplt.subplot(2,2,3)\nplt.plot(results.history['loss'])\nplt.plot(results.history['val_loss'])\nplt.title('Loss vs Epoch')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.tight_layout()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T15:28:21.149403Z","iopub.execute_input":"2023-12-21T15:28:21.150233Z","iopub.status.idle":"2023-12-21T15:28:21.895987Z","shell.execute_reply.started":"2023-12-21T15:28:21.150189Z","shell.execute_reply":"2023-12-21T15:28:21.894922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K.clear_session()\nraw_predictions = model.predict(test_ds)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T15:28:21.897573Z","iopub.execute_input":"2023-12-21T15:28:21.898055Z","iopub.status.idle":"2023-12-21T15:29:34.120585Z","shell.execute_reply.started":"2023-12-21T15:28:21.898017Z","shell.execute_reply":"2023-12-21T15:29:34.119599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.where(raw_predictions < 0.5, 0, 1)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-21T15:29:34.122518Z","iopub.execute_input":"2023-12-21T15:29:34.12337Z","iopub.status.idle":"2023-12-21T15:29:47.014035Z","shell.execute_reply.started":"2023-12-21T15:29:34.123324Z","shell.execute_reply":"2023-12-21T15:29:47.013092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = [images[0].numpy() for images in test_ds.take(1)]\n# Looking at an example before creating saving outputs as image.\nplt.subplot(1,2,1)\nplt.axis('off')\nplt.imshow(image[0]) # Using index 0 because it is in shape of (1, 256, 256, 1)\nplt.subplot(1,2,2)\nplt.axis('off')\nplt.imshow(predictions[0], cmap='gray')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T15:29:47.020296Z","iopub.execute_input":"2023-12-21T15:29:47.020727Z","iopub.status.idle":"2023-12-21T15:29:47.371498Z","shell.execute_reply.started":"2023-12-21T15:29:47.020695Z","shell.execute_reply":"2023-12-21T15:29:47.369914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists('predictions'):\n    os.makedirs('predictions')\n\n# loop through the predictions and save each one as an image\nfor i, pred in tqdm(enumerate(predictions)):\n    pred = (pred * 255).astype(np.uint8)\n    image = Image.fromarray(pred.squeeze())\n    filename = f\"prediction_{i}.png\"\n    image.save(os.path.join('predictions', filename))","metadata":{"execution":{"iopub.status.busy":"2023-12-21T15:29:47.374078Z","iopub.execute_input":"2023-12-21T15:29:47.375182Z","iopub.status.idle":"2023-12-21T15:29:48.807901Z","shell.execute_reply.started":"2023-12-21T15:29:47.375119Z","shell.execute_reply":"2023-12-21T15:29:48.806812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_folder_path = os.path.join(os.getcwd(), 'predictions')\npred_images_path = np.sort([os.path.join(pred_folder_path, i) for i in os.listdir(pred_folder_path) if i.endswith('.png')])\nplot_segmentation_images(test_images_path, pred_images_path, size=256, Random=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T15:29:48.809442Z","iopub.execute_input":"2023-12-21T15:29:48.809952Z","iopub.status.idle":"2023-12-21T15:29:56.001662Z","shell.execute_reply.started":"2023-12-21T15:29:48.809905Z","shell.execute_reply":"2023-12-21T15:29:56.000398Z"},"trusted":true},"execution_count":null,"outputs":[]}]}